{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `generate_labels`\n",
    "This script generates images to label via Amazon SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import imageio\n",
    "import scipy.io as sio\n",
    "from scipy.special import comb\n",
    "\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping, TensorBoard\n",
    "from keras.losses import mean_squared_error\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras.models import load_model\n",
    "from keras.layers import Conv2D, Input\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import os\n",
    "import time\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "os.environ['IMAGEIO_FFMPEG_EXE'] = '/home/twd/.local/bin/ffmpeg'\n",
    "\n",
    "import json\n",
    "\n",
    "import sys\n",
    "sys.path.append('../ratception/pose_clusters/')\n",
    "sys.path.append('../ratception/')\n",
    "\n",
    "import processing\n",
    "from processing import plot_markers_3d\n",
    "import ops\n",
    "from generator import DataGenerator\n",
    "from generator_aux import DataGenerator_downsample\n",
    "\n",
    "from losses import mask_nan_keep_loss, mask_nan_keep_loss_safe, metric_dist_max\n",
    "import nets\n",
    "\n",
    "\n",
    "import serve_data\n",
    "import tensorflow as tf\n",
    "\n",
    "from six.moves import cPickle\n",
    "\n",
    "import matplotlib\n",
    "#matplotlib.use(\"Agg\") #for writing figure videos\n",
    "%matplotlib notebook\n",
    "%load_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's load in the mocap data, together with pointers to the correct frames. For now, this is the same across all cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTSDIR = './results/calibrd4_50frames_cams356/'\n",
    "# Create directory if it doesn't already exist\n",
    "\n",
    "directory = RESULTSDIR\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "    \n",
    "CONFIG_PARAMS = {}\n",
    "\n",
    "CONFIG_PARAMS['BASEDIR'] = '/media/twd/Fast/data/calib_rd4_hires/'\n",
    "CONFIG_PARAMS['RESULTSDIR'] = RESULTSDIR\n",
    "CONFIG_PARAMS['datadir'] = os.path.join(CONFIG_PARAMS['BASEDIR'],'New_preprocessed')\n",
    "CONFIG_PARAMS['viddir'] = '/media/twd/Fast/data/calib_rd4_hires/Video/'\n",
    "CONFIG_PARAMS['datafile'] = ['hires1_cam3_RealMatchedFrames.mat',\n",
    "                             'hires1_cam5_RealMatchedFrames.mat',\n",
    "                             'hires1_cam6_RealMatchedFrames.mat']\n",
    "CONFIG_PARAMS['INPUT_WIDTH'] = 1280\n",
    "CONFIG_PARAMS['INPUT_HEIGHT'] = 1024\n",
    "CONFIG_PARAMS['OUTPUT_WIDTH'] = 1280\n",
    "CONFIG_PARAMS['OUTPUT_HEIGHT'] = 1024\n",
    "CONFIG_PARAMS['CROP_HEIGHT'] = (0,1024)\n",
    "CONFIG_PARAMS['CROP_WIDTH'] = (20,1300)\n",
    "CONFIG_PARAMS['N_CHANNELS_IN'] = 3\n",
    "CONFIG_PARAMS['N_CHANNELS_OUT'] = 20\n",
    "CONFIG_PARAMS['BBOX_WIDTH'] = 1280\n",
    "CONFIG_PARAMS['BBOX_HEIGHT'] = 1024\n",
    "\n",
    "CONFIG_PARAMS['CAMNAMES'] = ['CameraE','CameraS','CameraU2']\n",
    "CONFIG_PARAMS['BATCH_SIZE'] = 1\n",
    "\n",
    "CONFIG_PARAMS['WORKERS'] = 12\n",
    "CONFIG_PARAMS['MAX_QUEUE_SIZE'] = 12\n",
    "\n",
    "CONFIG_PARAMS['SIGMA'] = 10\n",
    "  \n",
    "CONFIG_PARAMS['EPOCHS'] = 5\n",
    "CONFIG_PARAMS['VERBOSE'] = 1\n",
    "CONFIG_PARAMS['lr'] = 1e-3\n",
    "CONFIG_PARAMS['loss'] = mean_squared_error\n",
    "CONFIG_PARAMS['metric'] = 'mse'#metric_dist_max\n",
    "CONFIG_PARAMS['net'] = nets.unet2d_fullbn\n",
    "CONFIG_PARAMS['TILEFAC'] = 1\n",
    "CONFIG_PARAMS['DOWNFAC'] = 1\n",
    "\n",
    "CONFIG_PARAMS['IMMODE'] = 'video'\n",
    "\n",
    "# CONFIG_PARAMS['NEW_N_CHANNELS_OUT'] = 9\n",
    "# CONFIG_PARAMS['NEW_LAST_KERNEL_SIZE'] = (3,3)\n",
    "\n",
    "#CONFIG_PARAMS['WEIGHTS'] = '/home/twd/Dropbox/autoencoder/v3.0/results/unet2d_6cams_triangulate/unet2d_6cams/training_weights3_validloss1.05e-4.hdf5'\n",
    "#write config file\n",
    "# processing.write_config(RESULTSDIR,CONFIG_PARAMS,\n",
    "#                         \"fine tuning chihuahua 2D w/ the same samples used for 3D fine tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "samples_, datadict_, datadict_3d_, data_3d_ = serve_data.prepare_data(CONFIG_PARAMS, com_flag=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to preload handles to each video file for quick access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: Ignoring mp4 files numbered above 70000\n",
      "NOTE: Ignoring mp4 files numbered above 70000\n",
      "NOTE: Ignoring mp4 files numbered above 70000\n"
     ]
    }
   ],
   "source": [
    "vids = {}\n",
    "vid_dir_flag = True\n",
    "if CONFIG_PARAMS['IMMODE'] == 'video':\n",
    "    vids = {}\n",
    "    for i in range(len(CONFIG_PARAMS['CAMNAMES'])):\n",
    "        if vid_dir_flag:\n",
    "            addl = ''\n",
    "        else:\n",
    "            addl = os.listdir(os.path.join(CONFIG_PARAMS['viddir'],CONFIG_PARAMS['CAMNAMES'][i]))[0]\n",
    "        vids[CONFIG_PARAMS['CAMNAMES'][i]] = \\\n",
    "        processing.generate_readers(CONFIG_PARAMS['viddir'],\n",
    "                                    os.path.join(CONFIG_PARAMS['CAMNAMES'][i],addl),\n",
    "                                    maxopt=70000, extension='.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(CONFIG_PARAMS['CAMNAMES'])):\n",
    "#     if CONFIG_PARAMS['IMMODE'] == 'video':\n",
    "#         vids[CONFIG_PARAMS['CAMNAMES'][i]] = processing.generate_readers(CONFIG_PARAMS['viddir'],CONFIG_PARAMS['CAMNAMES'][i],\n",
    "#                                                                         maxopt=70000)\n",
    "    if CONFIG_PARAMS['IMMODE'] == 'tif':\n",
    "        vids[CONFIG_PARAMS['CAMNAMES'][i]] = os.path.join(CONFIG_PARAMS['viddir'],CONFIG_PARAMS['CAMNAMES'][i],'tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now set up our generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "#NOTE: SETTING VALIDATION OT RANDOM SHUFFLE\n",
    "params = {'dim_in': (CONFIG_PARAMS['INPUT_HEIGHT'],CONFIG_PARAMS['INPUT_WIDTH']),\n",
    "          'n_channels_in': CONFIG_PARAMS['N_CHANNELS_IN'],\n",
    "          'dim_out': (CONFIG_PARAMS['OUTPUT_HEIGHT'],CONFIG_PARAMS['OUTPUT_WIDTH']),\n",
    "          'batch_size': CONFIG_PARAMS['BATCH_SIZE'],\n",
    "          'n_channels_out': CONFIG_PARAMS['N_CHANNELS_OUT'],\n",
    "          'out_scale': CONFIG_PARAMS['SIGMA'],\n",
    "          'camnames': CONFIG_PARAMS['CAMNAMES'],\n",
    "          'crop_width': CONFIG_PARAMS['CROP_WIDTH'],\n",
    "          'crop_height': CONFIG_PARAMS['CROP_HEIGHT'],\n",
    "          'bbox_dim': (CONFIG_PARAMS['BBOX_HEIGHT'],CONFIG_PARAMS['BBOX_WIDTH']),\n",
    "          'downsample': CONFIG_PARAMS['DOWNFAC'],\n",
    "          'immode': CONFIG_PARAMS['IMMODE'],\n",
    "          'shuffle': True}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the samples used for 3D chihuahua fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = datadict_\n",
    "labels_3d = datadict_3d_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition = {}\n",
    "partition['train'] = np.random.choice(samples_,size=(50,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generators\n",
    "train_generator = DataGenerator_downsample(partition['train'], labels, vids, **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/twd/anaconda3/envs/keras2.2.2/lib/python3.6/site-packages/scipy/io/matlab/miobase.py:414: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  arr[empties] = ' '\n"
     ]
    }
   ],
   "source": [
    "train_generator.save_for_dlc(RESULTSDIR + 'imDir/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
